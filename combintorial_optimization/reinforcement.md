---
sort: 4
---
# 深度强化学习(Deep Reinforcement Learning)

## 人工智能
![人工智能关系](..\img\drlclassification.jpg)   
- 机器学习：使用数据或以往的经验来改善系统自身的性能。
- 监督学习：根据已有的数据集，知道输入和输出结果之间的关系。根据这种已知的关系，训练得到一个最优的模型。通过训练，让机器可以自己找到特征和标签之间的联系，在面对只有特征没有标签的数据时，可以判断出标签。适用于回归（针对连续型变量）、分类（针对离散型变量）问题。
- 无监督学习：不知道数据集中数据、特征之间的关系，而是要根据聚类或一定的模型得到数据之间的关系。适用于聚类问题。
- 深度学习：一切运用了神经网络作为参数结构进行优化的机器学习算法。
- 强化学习：不仅能利用现有数据，还可以**通过对环境的探索获得新数据**，并且利用新数据循环往复地更新迭代现有模型的机器学习算法。
- 深度强化学习 = 深度学习 + 强化学习

## 强化学习
### what? & why？
**强化学习讨论的问题是一个智能体(agent)怎么在一个复杂不确定的环境(environment)里面去极大化它能获得的奖励。**相较于监督学习中的训练数据含有标签，强化学习存在一个问题：没有标签来说明现在的决策是正确还是错误，必须等到交互结束才可能说明，这个交互可能十秒过后才结束。现在这个决策到底对最后交互结束的反馈是否有帮助，其实是不清楚的。这里就面临**延迟奖励**(delayed reward)，所以就使得训练这个网络非常困难。  
在强化学习过程中，没有监督者(supervisor)，只有一个奖励信号，并且这个奖励信号是延迟的，环境会在很久以后告诉你之前你采取的行为到底是不是有效的。Agent在这个强化学习里面学习非常困难，因为无法得到即时反馈。
- 当采取一个行为过后，如果使用监督学习，立刻就可以获得一个指引，告诉agent现在做出了一个错误的决策，正确的决策应该是什么。
- 在强化学习里面，环境可能会告诉agent一个决策是错误的，但是它并不会告诉agent正确的决策是什么。而且更困难的是，它可能是在一两分钟过后告诉agent这个决策是错误的。  

```note
**为什么使用强化学习？**非常重要的一点原因就是强化学习得到的模型可以有超人类的表现。  
- 监督学习使用的有标签的数据是人为标注的。所以可以确定算法的上限就是人类的表现，人类的标注决定了训练的结果永远不可能超越人类。
- 对于强化学习，agent在环境里自己探索，有非常大的潜力，可以获得超越人类的表现。

解决现实问题时，通常使用两种方法的结合。只是用监督学习并不能超越标注数据的限制，只使用强化学习在学习初期会走很多弯路导致学习速度减慢。例如：Alpha Go首先使用深度学习的方式学习现有的棋谱，在棋谱学习完毕后，想要进一步加强智能体的决策能力，超越人类的能力范畴，这时引入强化学习的方法通过自博弈的方式进一步学习。
```

### how?
![强化学习交互过程](..\img\drl1.png)   
强化学习的研究依赖agent和环境的交互。在强化学习过程中，agent跟环境一直在**交互**。Agent在环境里面获取到**状态**(state)，agent会利用这个状态输出一个**动作**(action)，一个决策。然后这个决策会放到环境之中去，环境会根据agent采取的决策，输出**下一个状态**以及当前的这个决策得到的**奖励**(reward)。Agent的目的就是为了尽可能多地从环境中获取奖励。  
这个agent与环境的交互过程可以规范为一个马尔可夫决策过程(Markov Decision Process, MDP)，一个MDP可以表示为一个四元组的形式$$<S,A,R,P>$$：  
- 状态(State)：状态是对环境的描述，在智能体做出动作后，状态会发生变化，且演变具有马尔可夫性质。MDP所有状态的集合是状态空间。状态空间可以是离散或连续的。  
- 动作(Action)：动作是对智能体行为的描述，是智能体决策的结果。MDP所有可能动作的集合是动作空间。动作空间可以是离散或连续的。
- 奖励(Reward)：智能体给出动作后环境对智能体的反馈。是当前时刻状态、动作和下个时刻状态的标量函数。
- 状态转移概率(Probability)：在$$t$$时刻，处于$$s_t$$的状态，选择了$$a_t$$的动作的情况下，状态由$$s_t$$转移到$$s_{t+1}$$并且获得奖励$$r_t$$的概率。  

## 应用实例


## 参考
- [easy-rl：总结了强化学习的一些基础算法和概念。](https://datawhalechina.github.io/easy-rl/#/)   
- [deeplizard：适合作为第一个上手的强化学习pytorch编程案例，配合视频食用更佳。](https://deeplizard.com/)  
- [deeplizard 国内搬运视频。](https://www.bilibili.com/video/BV15K411N7CF?spm_id_from=333.999.0.0)